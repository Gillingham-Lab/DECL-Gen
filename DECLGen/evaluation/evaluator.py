import base64
import io
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.colors as colors
from matplotlib.markers import MarkerStyle
from matplotlib import path as mpath
import mpl_toolkits.mplot3d.art3d as art3d
from matplotlib.patches import Circle
import numpy as np
import os
import pandas as pd
from rdkit import Chem
from rdkit.Chem import AllChem, Draw
from rdkit import RDLogger
import seaborn as sns
from typing import Sequence, List, Tuple, Optional

from DECLGen.exceptions import EvaluationFileDoesNotExist, EvaluationInvalidFileFormat


class Evaluator:
    count_table: pd.DataFrame
    count_table_purified: pd.DataFrame
    count_table_reduced: pd.DataFrame
    replicates: int
    count_columns: List[str]
    codon_columns: List[str]
    codon_rank_columns: List[str]
    diversity_elements_count: int

    unique_codons: int
    all_counts: int
    valid_codons: int
    valid_counts: int


    def __init__(self, *results, progressBar = None):
        self.count_table = None
        self.progressBar = progressBar
        self.load_counts(results)

    def merge_properties(self, properties: pd.DataFrame):
        self.library_size = len(properties)

        self.count_table_purified = properties.merge(self.count_table, on="Codon-Combination", how="left")
        self.count_table_purified.sort_values(by="Codon-Combination", inplace=True)
        self.count_table_purified.reset_index(drop=True)

        self.diversity_elements_count = len(self.count_table_purified["Codon-Combination"].iloc[0].split("-"))

        # We do not know the codon column names. Thats why we create our own, and rank them for plotting
        self.codon_columns = ["Codon_{}".format(x+1) for x in range(self.diversity_elements_count)]
        self.codon_rank_columns = ["CodonRank_{}".format(x+1) for x in range(self.diversity_elements_count)]
        codons =  pd.DataFrame(
            self.count_table_purified["Codon-Combination"].str.split('-').tolist(),
            columns = self.codon_columns
        )
        codon_ranks = codons.rank(method="dense")
        codon_ranks.columns = self.codon_rank_columns

        # Join the codon and the codon ranks back
        self.count_table_purified = self.count_table_purified.join(codons)
        self.count_table_purified = self.count_table_purified.join(codon_ranks)

        self.count_table_reduced = self.count_table_purified.dropna()
        self.count_table_reduced = self.count_table_reduced.sort_values(by=["MeanCounts", "StdDevCounts"], ascending=[False, True])
        self.count_table_reduced = self.count_table_reduced.reset_index(drop=True)

        self.count_table_purified = self.count_table_purified.fillna(0)
        self.count_table_purified = self.count_table_purified.sort_values(by=["MeanCounts", "StdDevCounts"], ascending=[False, True])
        self.count_table_purified = self.count_table_purified.reset_index(drop=True)

        # Statistics
        self.valid_codons = self.count_table_purified[self.count_table_purified["MeanCounts"] > 0]["Codon-Combination"].nunique()
        self.valid_counts = int(self.count_table_purified[self.count_columns].sum().sum())

        # Sort

    def load_counts(self, results: Sequence):
        """
        Loads given result count files and merges then into one dataframe, storing the mean and standard deviation of the counts.

        The original count columns are kept intact, but they are enumerated.
        :param results:
        :return:
        """
        result = None
        filename = None
        column = None
        columns = None
        count_columns = []
        count_column_names = []
        replicates = len(results)

        try:
            i = 0
            for filename in results:
                i+=1
                if self.progressBar is not None:
                    self.progressBar.update(i / replicates)

                df = pd.read_csv(filename, sep="\t")
                count_column_names.append(os.path.basename(filename))

                if column is None:
                    if "CountRel" in df.columns:
                        column = "CountRel"
                    elif "Count" in df.columns:
                        column = "Count"
                    else:
                        raise EvaluationInvalidFileFormat(
                            ("Cannot determine count column of result file {}. Make sure the file has been generated by " +
                            "declEval extract or declEval compare.").format(filename))

                    columns = [x for x in df.columns]
                else:
                    if [x for x in df.columns] != columns:
                        raise EvaluationInvalidFileFormat(
                            ("The columns of the result file {} does not match those loaded before. Make sure they " +
                            "were properly created.").format(filename))

                # If first result, just load in.
                if result is None:
                    result = df
                    new_column = column + "{}".format(i)
                    result.rename(columns={column: new_column}, inplace=True)
                    count_columns.append(new_column)
                    continue

                # Merge if one result has already been loaded
                result = result.merge(df, on="Codon-Combination", how="outer")
                new_column = column + "{}".format(i)
                result.rename({column: new_column}, axis="columns", inplace=True)
                count_columns.append(new_column)

            # Fill empty fields with 0
            result.fillna(0, inplace=True)

            # Save mean and standard deviation
            result["MeanCounts"] = result[count_columns].mean(axis=1)
            result["StdDevCounts"] = result[count_columns].std(axis=1)
            result.sort_values(by=["MeanCounts", "StdDevCounts"], ascending=False, inplace=True)

        except FileNotFoundError:
            raise EvaluationFileDoesNotExist("Result file <{}> does not exist.".format(filename))

        # Save
        self.count_table = result
        self.replicates = replicates
        self.count_columns = count_columns
        self.count_column_names = count_column_names

        self.count_table.rename(dict(zip(self.count_columns, self.count_column_names)), axis="columns", inplace=True)
        self.count_columns, self.count_column_names = self.count_column_names, self.count_columns

        # Statistics
        self.unique_codons = self.count_table["Codon-Combination"].nunique()
        self.all_counts = int(self.count_table[self.count_columns].sum().sum())

    def replicates_scatter(self, scale = None):
        if self.replicates <= 1:
            return

        with io.BytesIO() as image_stream:
            ax = sns.pairplot(
                self.count_table_purified[self.count_columns], diag_kind="kde", kind="reg", markers="+",
                plot_kws=dict(),
                diag_kws=dict(shade=True),
            )

            plt.savefig(image_stream, format="png")
            img_base64 = base64.b64encode(image_stream.getvalue())
            plt.close()

        return img_base64

    def count_histogram(self):
        with io.BytesIO() as image_stream:
            ax = sns.kdeplot(self.count_table_reduced["MeanCounts"], shade=True, legend="mean counts")

            plt.savefig(image_stream, format="png")
            img_base64 = base64.b64encode(image_stream.getvalue())
            plt.close()

        return img_base64

    def two_element_3d_scatter(self, top_hits = None, codon_x = 1, codon_y = 2, anchored=False, project_on_z_plane=False):
        codon_x = self.codon_rank_columns[codon_x - 1]
        codon_y = self.codon_rank_columns[codon_y - 1]

        df = self.count_table_reduced

        if top_hits is not None:
            df_reduced = df.nlargest(top_hits, "MeanCounts")
        else:
            df_reduced = df

        with io.BytesIO() as image_stream:
            fig, ax = Scatter3D(
                df_reduced, codon_x, codon_y, "MeanCounts", c="MeanCounts", s="MeanCounts", complete_data=df,
                project_on_z_plane=project_on_z_plane,
                anchored=anchored,
            )

            fig.savefig(image_stream, format="png")
            img_base64 = base64.b64encode(image_stream.getvalue())
            plt.close()

        return img_base64

    def iter_hits(self, top=None):
        lg = RDLogger.logger().setLevel(RDLogger.ERROR)

        i = 0
        for index, row in self.count_table_reduced.iterrows():
            i += 1

            if i > top:
                break

            yield Hit(i, row)

        lg = RDLogger.logger().setLevel(RDLogger.INFO)

class Hit:
    rank: int
    row: pd.Series

    def __init__(self, rank, row):
        self.rank = rank
        self.row = row

    @property
    def counts(self):
        return self.row["MeanCounts"]

    @property
    def codons(self):
        return self.row["Codon-Combination"]

    @property
    def smiles(self):
        return self.row["Canonical smiles"]

    def draw(self) -> str:
        m = Chem.MolFromSmiles(self.row["Canonical smiles"])
        AllChem.Compute2DCoords(m)

        with io.BytesIO() as image_stream:
            img = Draw.MolToImage(m, size=(300, 300), kekulize=True, wedgeBonds=True)
            img.save(image_stream, format="png")

            img_base64 = base64.b64encode(image_stream.getvalue())

        return img_base64



def Scatter3D(
        data: pd.DataFrame,
        x: str, y: str, z: str,
        ax=None,
        anchored: bool=False,
        c: str=None,
        s: str=None,
        project_on_x_plane: bool=False,
        project_on_y_plane: bool=False,
        project_on_z_plane: bool=False,
        complete_data: pd.DataFrame=None,
        azim = -120
):
    if ax is None:
        fig = plt.figure()
        ax = fig.add_subplot(1, 1, 1, projection='3d', azim=azim)

    lim_data = complete_data if complete_data is not None else data
    x_lim = lim_data[x].min(), lim_data[x].max()
    y_lim = lim_data[y].min(), lim_data[y].max()
    z_lim = lim_data[z].min(), lim_data[z].max()

    color_kwargs = {}
    if c is not None:
        color_kwargs = {"c": data[c], "cmap": "plasma", "norm": colors.PowerNorm(gamma=1),}

    size_kwargs = {}
    if s is not None:
        size_kwargs = {"s": (data[s] / data[s].max()) ** 2 * 100}

    if project_on_z_plane is True:
        z_projection = ax.scatter(
            data[x], data[y], z_lim[0], c="lightgray", depthshade=False,
            **size_kwargs,
            zorder=0,
        )

    if project_on_y_plane is True:
        y_projection = ax.scatter(
            data[x], y_lim[1], data[z], c="lightgray", depthshade=False,
            **size_kwargs,
            zorder=0,
        )

    if project_on_x_plane is True:
        y_projection = ax.scatter(
            x_lim[1], data[y], data[z], c="lightgray", depthshade=False,
            **size_kwargs,
            zorder=0,
        )

    if anchored is True:
        for _, point in data.iterrows():
            ax.plot([point[x], point[x]], [point[y], point[y]], [0, point[z]],
                    color='grey', linestyle='dashed', zorder=-.5, linewidth=1)

    scatter = ax.scatter(
        data[x],
        data[y],
        data[z],
        depthshade=False,
        **color_kwargs,
        **size_kwargs,
        zdir="z",
        zorder=10,
    )

    if c is not None:
        cbar = fig.colorbar(scatter)

    ax.set_xlabel(x)
    ax.set_ylabel(y)
    ax.set_zlabel(z)

    ax.set_xlim(x_lim)
    ax.set_ylim(y_lim)
    ax.set_zlim(z_lim)

    ax.set_xticks([x for x in np.arange(lim_data[x].min(), lim_data[x].max() + 1, lim_data[x].max() // 4)])
    ax.set_yticks([x for x in np.arange(lim_data[y].min(), lim_data[y].max() + 1, lim_data[y].max() // 4)])

    return fig, ax



"""bottom = np.zeros_like(df_rnk["Codon1"])

sc = ax.scatter(df_rnk["Codon1"], df_rnk["Codon2"], df_val[column], c=df_val[column], cmap="YlGnBu",
                norm=colors.PowerNorm(gamma=1.5))
cbar = fig.colorbar(sc)
ax.set_xlabel("Codon1")
ax.set_ylabel("Codon2")
ax.set_zlabel("Counts")
plt.savefig(image_stream, format="png")
plt.close()
img_base64 = base64.b64encode(image_stream.getvalue())"""